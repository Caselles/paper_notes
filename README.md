Inspired by [Adrian Colyer][1], [Denny Britz][2] and [Daniel Seita][3] 

This contains my notes for research papers that are relevant for my PhD on Machine Learning for Robotics. First, I list papers that I've read and papers that I want to read. Then, read papers are numbered on a (1) to (5) scale where a (1) means I have only barely skimmed it, while a (5) means I feel
confident that I understand almost everything about the paper. The links
here go to my paper summaries if I have them, otherwise those papers are on my
**TODO** list.

Contents:

- [Machine Learning for Robotics](#machine-learning-for-robotics)
    - [Papers I have read](#papers-i-have-read)
    - [Papers I want to read](#papers-i-want-to-read)
- [Questions for which I need the answer](#questions-for-which-i-need-the-answer)

# Machine Learning for Robotics

## Papers I've read

- [Learning to Act by Predicting the Future](https://github.com/Caselles/paper_notes/blob/master/read_papers/learning_to_act_by_predicting_the_future.md) (5)
- [Universal Value Function Approximators](https://github.com/Caselles/paper_notes/blob/master/read_papers/universal_value_function_approximators.md) (4)
- [Horde: A Scalable Real-time Architecture for Learning Knowledge from Unsupervised Sensorimotor Interaction](https://github.com/Caselles/paper_notes/blob/master/read_papers/horde_a_scalable_real_time.md) (5)
- [Learning by Playing â€“ Solving Sparse Reward Tasks from Scratch](https://github.com/Caselles/paper_notes/blob/master/read_papers/learning_by_playing_solving_sparse_reward_tasks_from_scratch.md) (3)
- [Reinforcement Learning with Unsupervised Auxiliary Tasks](https://github.com/Caselles/paper_notes/blob/master/read_papers/reinforcement_learning_with_unsupervised_auxiliary_tasks.md) (4)
- [Successor Features for Transfer in Reinforcement Learning
](https://github.com/Caselles/paper_notes/blob/master/read_papers/successor_features_for_transfer_in_reinforcemen_learning.md) (4)
- [Hindsight Experience Replay](https://github.com/Caselles/paper_notes/blob/master/read_papers/hindsight_experience_replay.md) (4)
- [Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks](https://github.com/Caselles/paper_notes/blob/master/read_papers/model_agnostic_meta_learning_for_fast_adaptation_of_deep_networks.md) (4)
- [Meta-Learning and Universality: Deep Representations and Gradient Descent can Approximate any Learning Algorithm](https://github.com/Caselles/paper_notes/blob/master/read_papers/meta_learning_and_universality_deep_representations_and_gradient_descent_can_approximate_any_learning_algorithm.md) (2)
- [A Distributional Perspective on Reinforcement Learning](https://github.com/Caselles/paper_notes/blob/master/read_papers/a_distributional_perspective_on_reinforcement_learning.md) (4)
- [Transfer for Reinforcement Learning Domains: A Survey](https://github.com/Caselles/paper_notes/blob/master/read_papers/transfer_for_reinforcement_learning_domains_a_survey.md) (3)
- [World Models](https://github.com/Caselles/paper_notes/blob/master/read_papers/world_models.md) (4)
- [Simple random search provides a competitive approach to reinforcement learning](https://github.com/Caselles/paper_notes/blob/master/read_papers/simple_random_search_provides_a_competitive_approach%20to_reinforcement_learning.md) (5)
- [Levine's lecture on "what do to when you have a forward model ?"](https://github.com/Caselles/paper_notes/blob/master/read_papers/levine_lecture_what_to_do_when_you_have_a_forward_model.md) (5)
- [Trust Region Policy Optimization](https://github.com/Caselles/paper_notes/blob/master/read_papers/trust_region_policy_optimization.md) (4)
- [Proximal Policy Optimization](https://github.com/Caselles/paper_notes/blob/master/read_papers/proximal_policy_optimization.md) (4)
- [Embed to Control: A Locally Linear Latent Dynamics Model for Control from Raw Images](https://github.com/Caselles/paper_notes/blob/master/read_papers/embed_to_control.md) (3)
- [Imagination-Augmented Agents for Deep Reinforcement Learning](https://github.com/Caselles/paper_notes/blob/master/read_papers/imagination_augmented_agents_for_deep_reinforcement_learning.md) (3)
- [Deep Successor Reinforcement Learning](https://github.com/Caselles/paper_notes/blob/master/read_papers/deep_successor_reinforcement_learning.md) (4)
- [Learning to Navigate in Complex Environments](https://github.com/Caselles/paper_notes/blob/master/read_papers/learning_to_navigate_in_complex_environments.md) (4)
- [Universal Option Models](https://github.com/Caselles/paper_notes/blob/master/read_papers/universal_options_model.md) (3)
- [Options: Temporal abstraction in Reinforcement Learning](https://github.com/Caselles/paper_notes/blob/master/read_papers/options_precup.md) (4)


## Papers I want to read

- FeUdal Networks for Hierarchical Reinforcement Learning
- Diversity is All You Need: Learning Skills without a Reward Function
- Learning to Search Better than Your Teacher
- Transfer in Variable-Reward Hierarchical Reinforcement Learning
- Curriculum Learning
- Theoretical TL papers from TL survey
- DRL that matters
- CMA-ES
- Action-Conditional Video Prediction using Deep Networks in Atari Games

# Questions for which I need the answer

[I need the answers to these questions.](https://github.com/Caselles/paper_notes/blob/master/read_papers/questions_unanswered.md) Any help is welcome ! Reach me at casellesdupre.hugo@gmail.com

[1]:https://blog.acolyer.org/about/
[2]:https://github.com/dennybritz/deeplearning-papernotes
[3]:https://github.com/DanielTakeshi/Paper_Notes#2018-rlil-papers
